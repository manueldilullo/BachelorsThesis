\section{Abstract}  \label{intro_abstract}
Il Natural Language Processing (NLP) è una branca dell'intelligenza artificiale in continuo sviluppo. I task che fanno parte di quest'area vengono affrontati tutti i giorni quando compiamo azioni che ormai ci sono naturali. Quando chiediamo qualcosa al nostro assistente digitale (es. Siri, Google Assistant, Alexa) oppure quando ci colleghiamo ad internet e utilizziamo un qualsiasi motore di ricerca per leggere le notizie della giornata, il sistema con il quale ci stiamo interfacciando ha il compito di interpretare la nostra richiesta ed elaborare un piano d'azione per produrre una risposta che possa essere per noi soddisfacente e altresì disponibile in tempi ragionevoli.

% Supponiamo di aprire il nostro browser preferito e di scrivere la seguente frase sulla barra di ricerca: \textbf{"Quando è stata scoperta l'America?"}. Il motore di ricerca sarà incaricato di rispondere al nostro quesito, non solo ricercando tutti i risultati contenenti i simboli che compongono la frase ma dovrà elaborare quest'ultima per comprendere il senso della domanda ed estrarre dall'immenso archivio dei contenuti presenti nel web tutti quelli che, secondo il sistema, sono i più accurati per rispondere all'interrogazione.

Il quantitativo di informazioni disponibili online è, però, infinitamente vasto e in continua crescita. Per citare dei numeri, soltanto nel 2021: sono state inviati circa 319.6 miliardi di email\textsuperscript{\cite{statista_email}}, inviati 100 miliardi di messaggi tramite WhatsApp\textsuperscript{\cite{statistics_whatsapp}}, 1.8 miliardi di persone utilizzano Facebook e 1.3 miliardi accedono alla sua app di messaggistica istantanea Facebook Messenger\textsuperscript{\cite{statistics_facebook}}. Inoltre, il \textit{World Economic Forum}\cite{wef_dataperday} stima che entro il 2025, la quantità di dati generati ogni giorno raggiungerà 463 exabyte a livello globale. Le informazioni che si stanno raccogliendo a livello globale stanno crescendo esponenzialmente e mentre questo accade, il numero di analisti umani sta crescendo solo linearmente - in altre parole, noi umani semplicemente non possiamo tenere il passo. Questo tesoro di dati non strutturati è così vasto che ormai non sappiamo nemmeno cosa non sappiamo.

Dall'esigenza di ottenere risposte a domande di varia natura in tempo utile, nasce l'idea di \textit{calcolo distribuito} e di \textit{sistema distribuito}. Si tratta di un concetto informatico, o meglio di una vera e propria branca dell’informatica, che studia i “sistemi distribuiti”, cioè “gruppi di computer” che collaborano tra loro per eseguire un determinato programma. Infatti, quasi la totalità dei software che lavorano coi Big Data, sono eseguiti in ambienti distribuiti di centinaia, se non migliaia di macchine connesse tra di loro. É da qui che nasce l'idea di base di questa Tesi, ovvero studiare uno degli strumenti maggiormente utilizzati per l'elaborazione del linguaggio naturale nel mondo dei Big Data: \textbf{Spark NLP}\footnote{Spark NLP: \href{https://nlp.johnsnowlabs.com/}{https://nlp.johnsnowlabs.com/}}. Spark NLP, sviluppato dal John Snow Lab, è ad oggi il framework più utilizzato dalle aziende che trattano task di Natural Language Processing, con il 33\% di utilizzatori sul mercato. 

Il progetto è partito dallo studio di questo framework attraverso l'utilizzo del linguaggio Python e dell'interfaccia PySpark\footnote{Documentazione PySpark: \href{https://spark.apache.org/docs/latest/api/python/index.html}{https://spark.apache.org/docs/latest/api/python/index.html}}. Inizialmente sono state sviluppate soluzioni a problemi di natura linguistica di vario genere come \textit{Tokenization}, \textit{Lemmatization} o \textit{PoS Tagging} e sono stati effettuati test su singole macchine con dataset di modeste dimensioni e l'uso di modelli pre-addestrati.
Sono stati utilizzati componenti built-in di Spark NLP, come \textit{Annotators} e \textit{Transformers}, per testare le funzionalità di questo strumento.

Una volta presa familiarità con il framework, si è deciso di osservare nel dettaglio il comportamento di Spark NLP su due task specifici: \textit{Text Classification} e \textit{Named Entity Recognition (NER)}. Il primo è definito come il processo di categorizzazione del testo in base al suo contenuto, compito presente in diversi campi come ad esempio la classificazione di email spam (classificazione binaria) o l'assegnazione di etichette a diversi articoli di notizie in base al loro contenuto (classificazione multi-classe). Il secondo è un sotto compito dell'estrazione di informazioni che cerca di localizzare e classificare elementi atomici nel testo in categorie predefinite come i nomi di persone, organizzazioni, luoghi, espressioni di tempi, quantità, ecc. Questi problemi sono approfonditi nel capitolo \ref{sperimentazione}.

Per entrambi i task, sono state sviluppate soluzioni che comprendono addestramento di un modello, test e valutazione di quest'ultimo. A partire dai modelli prodotti, sono stati studiati i punteggi ottenuti in termini di precisione, recall, accuratezza e F1-score (descritti nella sezione \ref{metriche}).

Spark NLP, però, offre prestazioni migliori in ambiente distribuito. Pertanto l'esecuzione del software è stata migrata su di un cluster di \clustersize{} macchine. Per fare ciò sono stati installati e configurati su ognuna di esse:
\begin{itemize}
    \item Ambiente Spark, sul quale si basa Spark NLP (approfondito nella sezione \ref{spark}).
    \item File system distribuito HDFS, per memorizzare in ambiente distribuito i dataset utilizzati e i modelli addestrati (descritto nel dettaglio al paragrafo \ref{hdfs}).
    \item Resource Manager YARN, per la gestione delle risorse durante l'esecuzione dell'applicazione (approfondito alla sezione \ref{yarn}). 
\end{itemize}

Una volta pronto il sistema distribuito, si è passati alla fase di analisi delle soluzioni sviluppate. I modelli addestrati sono stati testati su dataset di grandi dimensioni (> 700.000 esempi) e sono stati registrati i tempi di esecuzione ottenuti scalando il sistema, inizialmente utilizzando un solo worker e successivamente parallelizzando l'esecuzione su due macchine distinte.

Una volta a disposizione un set di risultati in termini di accuratezza e velocità di esecuzione, sono stati confrontati con quelli che attualmente formano lo stato dell'arte, valutando la validità del framework Spark NLP rispetto alle prestazioni fornite da altre soluzioni disponibili sul mercato.