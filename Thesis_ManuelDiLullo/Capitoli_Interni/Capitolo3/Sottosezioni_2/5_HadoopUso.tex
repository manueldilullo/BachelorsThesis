 \subsection{Utilizzo di Hadoop} \label{uso_hadoop}
Descritte le componenti HDFS e MapReduce, è possibile proseguire con illustrando come Hadoop è stato inserito all’interno del progetto di Tesi.

Come citato precedentemente, l’obiettivo ultimo è quello di testare soluzioni per la risoluzione di task di NLP in ambiente distribuito. Per fare ciò è stato configurato un database distribuito HDFS su di un cluster di 3 macchine connesse tre loro. Così facendo, tutte le macchine del sistema hanno accesso ai file contenenti i dataset di addestramento e di testing, ed ai modelli utilizzati (sia preaddestrati che allenati al momento della sperimentazione). Nel dettaglio, il nodo master del cluster ospita il NameNode, che si occupa della gestione del namespace del file system, mentre su ognuna delle altre macchine è stato invece allocato un processo DataNode, con lo scopo di delegare loro la manipolazione dei blocchi di dati secondo le indicazioni del NameNode.

Il concetto di MapReduce è invece ereditato da Apache Spark, framework su cui si basa Spark NLP, ovvero il soggetto di questo lavoro. Spark, come avviene con MapReduce, suddivide il processo in jobs e distribuisce questi ultimi tra i nodi del cluster migliorando le proprie prestazioni in fatto di distribuzione del carico e velocità di esecuzione. Nel capitolo successivo si entrerà nel dettaglio del funzionamento di Spark e di come è stato implementato all’interno del progetto.