\chapter{Conclusioni}
L'obiettivo di questo lavoro è quello di analizzare risultati a livello prestazionale ottenuti tramite l'utilizzo del framework Spark NLP per l'elaborazione del linguaggio naturale in ambiente distribuito; in particolar modo sui task di Text Classification e Named Entity Recognition.\\

Al fine di facilitare la comprensione del lavoro svolto, nel primo capitolo sono stati introdotti i temi trattati all'interno della Tesi ed è stata fatta una panoramica sugli scenari che richiedono una soluzione a problemi di Natural Language Processing.\\

All'interno del secondo capitolo, si è parlato proprio del concetto di NLP, entrando nel dettaglio delle fasi che questo processo attraversa e della complessità di alcuni problemi di elaborazione linguistica. Allacciandosi a questo discorso, si è proceduto a raccontare quali sono stati e quali sono ad oggi, gli approcci che gli scienziate e gli sviluppatori hanno nei confronti di questo problema, partendo dal famoso \textit{Test di Turing} fino ad arrivare al moderno Deep Learning. 
Questo \textit{excursus} è servito anche per trattare in maniera più dettagliata il concetto di Language Modeling e di Word Embedding, per poi porre l'attenzione alle tecnologie attualmente più implementate per la rappresentazione delle parole attraverso vettori numerici.
Questo capitolo ci è stato utile per comprendere l'ambiente in cui si colloca il progetto e conoscere i problemi di natura linguistica a cui fa riferimento.\\

Dal terzo capitolo si è passati ad esporre le tecnologie utilizzate all'interno del progetto. Dopo una rapida digressione sui concetti di calcolo distribuito e sistemi distribuiti, si è passati all'analisi di \textit{Apache Hadoop}, descrivendone il file system distribuito che esso offre (HDFS) e l'implementazione di MapReduce, per poi illustrare gli ambienti \textit{Apache Spark} e \textit{Spark NLP}, soggetti principali di questo lavoro. Nel dettaglio, degli ultimi due, sono state trattate le loro architetture, i vantaggi che offrono ed i problemi ai quali puntano a dare delle soluzioni. 
Una descrizione completa di questi strumenti è fondamentale per comprendere a pieno il perché si è deciso di studiarli e per facilitare la lettura del capitolo successivo.

Il capitolo si conclude con la descrizione dell'architettura distribuita sulla quale è stato eseguito il software sviluppato. É stato descritta la sua struttura fisica e logica, riportando dati riguardanti l'hardware utilizzato, il file system distribuito utilizzato e la configurazione dell'ambiente Spark.\\

Infine, nel capitolo quarto, è stata presentata la fase di sperimentazione, partendo dall'esposizione dei task di Text Classification e Named Entity Reconition e i quesiti che essi pongono, passando per la descrizione dei dataset utilizzati per l'addestramento dei modelli e per il testing di questi ultimi e concludendo con l'illustrare i componenti sui quali il software si basa. 
In particolar modo, riguardo a quest'ultimo punto, sono stati descritti i componenti di Spark NLP che sono stati utilizzati, i modelli che sono stati inclusi per la fase di embedding dei testi e come sono state costruite le pipeline che formano il processo di elaborazione dei record contenuti nei dataset.

Il capitolo si chiude con l'analisi dettagliata dei risultati ottenuti dalla soluzione sviluppata. Si è posta l'attenzione sui tempi di esecuzione ottenuti durante le fasi di addestramento e di testing, e sui valori di accuratezza raggiunti, approfondendo le differenze ottenute tra l'accuratezza vera e propria e l'\textit{F1-Score}, media armonica di precisione e recupero.

Questo lavoro è un punto di partenza per un proseguimento dello studio di questo framework. A partire dalla soluzione sviluppata è possibile divagare all'interno delle possibilità offerte da Spark NLP, magari aggiungendo una fase di preprocessing dei testi e andando a modulare più nel dettaglio le opzioni offerte da questo framework per un addestramento più efficace. Altre prospettive per il futuro sono quelle di risolvere i problemi riscontrati durante la parallelizzazione del lavoro e di testare prestazioni ottenute utilizzando altri modelli di embedding come RoBERTa\footnote{\href{https://arxiv.org/abs/1907.11692}{RoBERTa: A Robustly Optimized BERT Pretraining Approach}}, ALBERT\footnote{\href{https://arxiv.org/abs/1909.11942}{ALBERT: A Lite BERT for Self-supervised Learning of Language Representations}} o DistilBERT\footnote{\href{https://arxiv.org/abs/1910.01108}{DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter}}. 